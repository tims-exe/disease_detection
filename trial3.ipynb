{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365a81b8-ba06-4dd7-a3d4-5208cdbc1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a1689c-b254-4fb3-b481-2bc1ffbed1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset file path\n",
    "\n",
    "malignant_files = \"dataset/trial/Malignant\"\n",
    "normal_files = \"dataset/trial/Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93059d9a-55ad-4722-910a-061c131dd3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the images from the directories\n",
    "\n",
    "def load_images(directory, label):\n",
    "  images = []\n",
    "  labels = []\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "      img_path = os.path.join(directory, filename)\n",
    "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "      if img is not None:\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e357f39-e2e7-411e-a862-a26ec666ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal = 0\n",
    "# malignant = 1\n",
    "\n",
    "malignant_images, malignant_labels = load_images(malignant_files, label=1)\n",
    "normal_images, normal_labels = load_images(normal_files, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf8abae-61b9-4388-a04f-b1be868ca5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = malignant_images + normal_images\n",
    "labels = malignant_labels + normal_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f2a7ff-3e70-4361-9880-c966037d27bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ce5c6d-5b0d-4ecb-9d7b-f8af7a9b6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7221fb-4577-4440-bfbc-b259fdd42fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Malignant\": malignant_files,\n",
    "    \"Normal\": normal_files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f73701-9dc4-4fb2-8b02-e4cdaff5b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train :  (776, 128, 128)\n",
      "Shape of y_train_encoded :  [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.5251 - loss: 2146.7822 - val_accuracy: 0.8205 - val_loss: 60.0619\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.6615 - loss: 247.7907 - val_accuracy: 0.9551 - val_loss: 7.2765\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.8900 - loss: 22.8400 - val_accuracy: 0.9872 - val_loss: 1.7333\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 5.9265 - val_accuracy: 0.9744 - val_loss: 3.0338\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9832 - loss: 2.2727 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 981ms/step - accuracy: 0.9922 - loss: 0.1646 - val_accuracy: 1.0000 - val_loss: 9.5955e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 995ms/step - accuracy: 0.9964 - loss: 0.0510 - val_accuracy: 1.0000 - val_loss: 8.2217e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 997ms/step - accuracy: 0.9945 - loss: 0.2781 - val_accuracy: 0.9936 - val_loss: 0.1135\n",
      "Epoch 9/10\n",
      "\u001b[1m 7/20\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 959ms/step - accuracy: 0.9951 - loss: 0.0301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Input(shape=(128, 128, 1)),\n",
    "  Conv2D(32, (3, 3), activation = 'relu'),\n",
    "  MaxPooling2D((2,2)),\n",
    "  Conv2D(64, (3, 3), activation = 'relu'),\n",
    "  MaxPooling2D((2,2)),\n",
    "  Conv2D(128, (3, 3), activation = 'relu'),\n",
    "  MaxPooling2D((2,2)),\n",
    "  Flatten(),\n",
    "  Dense(512, activation = 'relu'),\n",
    "  Dropout(0.5),\n",
    "  Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes = 2)\n",
    "y_test_encoded = to_categorical(y_test, num_classes = 2)\n",
    "\n",
    "print(\"Shape of X_train : \", x_train.shape)\n",
    "print(\"Shape of y_train_encoded : \", y_train_encoded)\n",
    "\n",
    "history = model.fit(x_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "print(\"Training history : \", history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e24f49-e4f4-42f8-8e56-b071bed68374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0055\n",
      "Model Accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "y_test_encoded = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_encoded)\n",
    "#print(f'Test Loss: {test_loss}')\n",
    "#print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "print(\"Model Accuracy =\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf7cc4-0dad-47ba-8588-202f54a27171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path, target_size=(128, 128)):\n",
    "    #print(img_path)\n",
    "    img = image.load_img(img_path, target_size=target_size, color_mode='grayscale')\n",
    "    img_array = image.img_to_array(img)\n",
    "    plt.imshow(img_array.squeeze(), cmap='gray')\n",
    "    plt.title('CT Scan')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77aa3f-ef1c-4637-bc9a-4fec823f950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, img_path):\n",
    "  img_array = load_and_preprocess_image(img_path)\n",
    "  prediction = model.predict(img_array)\n",
    "  class_index = np.argmax(prediction, axis = 1)\n",
    "  return class_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857cb53-aab0-413e-b958-e55aea4a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['Normal', 'Malignant']\n",
    "\n",
    "test_img = 'dataset/trial/test/m2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b977e-422d-4934-a0d1-1df8aff85002",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_index = predict_image(model, test_img)\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "print(f'The model predicts that the image as : {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c46b28-3a13-481b-9e35-2bd54fa6d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0f896-1d8d-44e5-afa9-0c244773bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_image(img_path):\n",
    "    # Load the image in grayscale\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        # Resize the image to the required input size\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        # Normalize the image data to the range [0, 1]\n",
    "        img = img / 255.0\n",
    "        # Expand dimensions to match the model input shape\n",
    "        img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
    "        img = np.expand_dims(img, axis=0)   # Add batch dimension\n",
    "\n",
    "        # Display the image using matplotlib\n",
    "        plt.imshow(img[0, :, :, 0], cmap='gray')\n",
    "        plt.title(\"Loaded Image\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7c560-4d22-4a30-9bf5-cc77c705660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "img_path = 'dataset/trial/test/n3.jpg'\n",
    "image = load_single_image(img_path)\n",
    "\n",
    "# Now you can predict using your model\n",
    "prediction = model.predict(image)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "predicted_class = class_labels[predicted_label]\n",
    "\n",
    "print(\"Predicted label:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04b3e1-fba6-4496-aac9-1aa5dde78f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
